apiVersion: v1
kind: ConfigMap
metadata:
  name: deepseek-config
  namespace: wifire-kg
data:
  MODEL_PATH: "/models/deepseek-v3"
  MAX_INPUT_LENGTH: "4096"
  MAX_TOTAL_TOKENS: "8192"
  TEMPERATURE: "0.7"
  TOP_P: "0.95"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deepseek-llm
  namespace: wifire-kg
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: deepseek-llm
  template:
    metadata:
      labels:
        app: deepseek-llm
    spec:
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "nautilus.io/gitlab-issue"
        operator: "Exists"
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #       - matchExpressions:
      #         - key: nvidia.com/gpu
      #           operator: Exists
      containers:
      - name: deepseek-llm
        image: huggingface/transformers-pytorch-gpu:latest
        command: ["/bin/bash", "-c"]
        args:
          - |
            pip install --upgrade transformers torch fastapi uvicorn &&
            python3 -c "
            from transformers import AutoModelForCausalLM, AutoTokenizer
            import torch
            from fastapi import FastAPI
            import uvicorn
            from pydantic import BaseModel

            app = FastAPI()

            class CompletionRequest(BaseModel):
                prompt: str
                max_tokens: int = 1024
                temperature: float = 0.7

            model = AutoModelForCausalLM.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 
                                                        device_map='cpu',
                                                        trust_remote_code=True,
                                                        torch_dtype=torch.float32)
            tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',
                                                     trust_remote_code=True)

            @app.post('/v1/completions')
            async def generate(request: CompletionRequest):
                inputs = tokenizer(request.prompt, return_tensors='pt')
                outputs = model.generate(
                    **inputs, 
                    max_length=request.max_tokens,
                    temperature=request.temperature,
                    do_sample=True
                )
                return {'choices': [{'text': tokenizer.decode(outputs[0])}]}

            @app.get('/health')
            async def health():
                return {'status': 'healthy'}

            uvicorn.run(app, host='0.0.0.0', port=8080)
            "
        ports:
        - containerPort: 8080
        envFrom:
        - configMapRef:
            name: deepseek-config
        resources:
          requests:
            cpu: "16"
            memory: "256Gi"
          limits:
            cpu: "32"
            memory: "512Gi"
        volumeMounts:
        - name: model-storage
          mountPath: /models
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 300
          periodSeconds: 30
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 300
          periodSeconds: 30
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: deepseek-model-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: deepseek-llm
  namespace: wifire-kg
spec:
  type: ClusterIP
  selector:
    app: deepseek-llm
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: deepseek-model-pvc
  namespace: wifire-kg
spec:
  storageClassName: "rook-cephfs"
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: deepseek-ingress
  namespace: wifire-kg
  annotations:
    kubernetes.io/ingress.class: haproxy
spec:
  rules:
  - host: deepseek.nrp-nautilus.io
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: deepseek-api
            port:
              number: 8000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: deepseek-llm
            port:
              number: 8080
  tls:
  - hosts:
    - deepseek.nrp-nautilus.io

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: deepseek-api-code
  namespace: wifire-kg
data:
  deepseek_api.py: |
    from fastapi import FastAPI, HTTPException
    from pydantic import BaseModel
    import requests

    app = FastAPI()

    class Query(BaseModel):
        prompt: str
        max_tokens: int = 1024
        temperature: float = 0.7

    class Response(BaseModel):
        text: str

    @app.post("/generate")
    async def generate_text(query: Query):
        try:
            response = requests.post(
                "http://deepseek-llm:8080/v1/completions",
                json={
                    "prompt": query.prompt,
                    "max_tokens": query.max_tokens,
                    "temperature": query.temperature
                }
            )
            return Response(text=response.json()["choices"][0]["text"])
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/health")
    async def health():
        return {"status": "healthy"}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deepseek-api
  namespace: wifire-kg
spec:
  replicas: 1
  selector:
    matchLabels:
      app: deepseek-api
  template:
    metadata:
      labels:
        app: deepseek-api
    spec:
      containers:
      - name: deepseek-api
        image: python:3.9-slim
        command: ["/bin/bash", "-c"]
        args:
          - |
            pip install fastapi uvicorn requests pydantic &&
            cd /app &&
            uvicorn api.deepseek_api:app --host 0.0.0.0 --port 8000
        ports:
        - containerPort: 8000
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "1000m"
            memory: "2Gi"
        volumeMounts:
        - name: api-code
          mountPath: /app/api
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: api-code
        configMap:
          name: deepseek-api-code

---
apiVersion: v1
kind: Service
metadata:
  name: deepseek-api
  namespace: wifire-kg
spec:
  type: ClusterIP
  selector:
    app: deepseek-api
  ports:
  - port: 8000
    targetPort: 8000
    protocol: TCP
